## 面试记录

#### 数据结构与算法
1. 双指针 => 滑动窗口 （几乎每家公司都考了）
2. 动态规划 （走楼梯，找零钱，最长回文子序列）=> 备忘录，数学优化（分析成分比如能被几整除优化循环）
3. 递归
4. 数学题（比如概率期望，用程序模拟）
5. 二分搜索查找

##### 题目
1. LeetCode 03。 无重复字符的最长子串
2. LeetCode 490. The Maze 迷宫
3. 捡⾦币游戏。下图是个MxN的⽹格，其中每个格⼦都装了若⼲⾦币，现玩家有⼀次机会从start位置⾛到end位置去捡⾦币。每个格⼦⾦币已知，请为玩家规划⼀条路线[(x0, y0), ..., (xn, yn)]，使其能捡到最多的⾦币
4. 矩阵快速求和：给定⼀个n x m的矩阵M，实现快速求和函数fast_sum(M, i1, i2, j1, j2)，函数返回值是M的⼦矩阵Mi1~i2,j1~j2中所有元素的和。
5. 实现⼀个时间复杂度为O(n)，空间复杂度为O(1)的函数split_sort(A)。其中A是⼀个数组。假设a是A中的第⼀个元素，要求该函数返回A的⼀个重排列B，使得a在B中左边的元素都⼩于a，右边的元素都⼤于等于a。
6. 数组Arr=[a1, a2, ..., an]是个⽆序数组，请从其中选出3个数，组成⼀个各边之和最⼤的三⻆形。返回最⼤的边⻓和即可，如果⽆法找到符合条件的3个数则返回0。要求：算法时间复杂度不⼤于O(n2)。
7. pandas数据处理，sklearn算法应用，PIL和OPENCV包使用
8. 走迷宫，第一个口15min出去，第二个口25min回到洞口，第三个口50min回到洞口，算出去的期望
9. 10大排序算法

#### Python 
1. 单例模式：写法，原理，作用
2. 线程，进程，协程
3. python GIL 以及优化方式
4. python 类的继承 多态
5. pytorch 
    - torch.mul(a, b)是矩阵a和b对应位相乘，a和b的维度必须相等，比如a的维度是(1, 2)，b的维度是(1, 2)，返回的仍是(1, 2)的矩阵
    - torch.mm(a, b)是矩阵a和b矩阵相乘，比如a的维度是(1, 2)，b的维度是(2, 3)，返回的就是(1, 3)的矩阵
    - torch: add, concate, +
    - 广播机制
    - torch.reshape 可以改变张量的形状。 torch.squeeze 可以减少维度。torch.unsqueeze 可以增加维度。torch.transpose 可以交换维度。 
6. LRU机制，写法 
7. 哈希表去重
8. 装饰器


#### 机器学习算法
1. 贝叶斯算法，假设，贝叶斯公式
2. SVM算法：支持向量是什么？核的作用？核的选择？
3. KMEANS原理
4. 线性回归 => 逻辑回归
5. MSE => 方差 + 偏差 => trade-off => 过拟合，欠拟合
6. 交叉熵损失
7. ID3, c4.5, CART树
8. 集成学习：boosting, bagging
9. adaboosting, GBDT
10. XGB与GBDT的区别
11. XGB与lgbm的区别
12. 正则化: l1, l2的区别，作用，使用场景
13. 常用特征工程的方法
14. 维度灾难

#### 图像算法
1. RCNN => Fast RCNN => Faster RCNN 原理区别
2. SSD Yolo 原理区别
3. Focal loss
4. mosaic training
5. NMS细节
6. anchor box 设定
7. two-stage one-stage区别
8. 激活函数的区别：sigmoid, relu, leaky relu...
9. IOU的计算，各种其他的改进的IOU的区别:GIOU, CIOU, LDIOU
10. mAP的计算
11. 解释下深度可分离卷积
12. ResNet的原理以及变种：inception， resnext 等区别优缺点
13. tfidf
14. attention 和 transformer 见识下原理以及计算方式
15. 感受野计算，浅层和深层的区别
16. 各种优化器：RMSprop，Momentum，adam, NAG
17. BN层的原理以及作用
18. 数据增强的方法
19. 人脸检测时loss的改进：triplet loss, sphere Loss, arc face loss
